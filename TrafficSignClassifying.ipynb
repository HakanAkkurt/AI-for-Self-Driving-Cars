{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"TrafficSignClassifying.ipynb","provenance":[]},"accelerator":"GPU","interpreter":{"hash":"85e85cc404b86ffd5bd3fd94b6e61bb048a6a938b33759e8305278574ba46707"}},"cells":[{"cell_type":"code","execution_count":null,"source":["!git clone https://bitbucket.org/jadslim/german-traffic-signs"],"outputs":[],"metadata":{"id":"52678832"}},{"cell_type":"code","execution_count":2,"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import keras\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from tensorflow.keras.optimizers import Adam\r\n","from keras.utils.np_utils import to_categorical\r\n","from keras.layers import Dropout, Flatten\r\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","import pickle\r\n","import pandas as pd\r\n","import random\r\n","import cv2\r\n","import requests\r\n","from PIL import Image"],"outputs":[],"metadata":{"id":"6iQzxtltx-i6","executionInfo":{"status":"ok","timestamp":1632355652107,"user_tz":-120,"elapsed":3052,"user":{"displayName":"Hakan Akkurt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLEPpv1uGUTPBX1jWPMnVdbayenxwO02bYkBxtpA=s64","userId":"06064478302452357513"}}}},{"cell_type":"code","execution_count":null,"source":["np.random.seed(0)\r\n","\r\n","with open('/content/german-traffic-signs/train.p', 'rb') as f:\r\n","    train_data = pickle.load(f)\r\n","\r\n","with open('/content/german-traffic-signs/valid.p', 'rb') as f:\r\n","    val_data = pickle.load(f)\r\n","\r\n","with open('/content/german-traffic-signs/test.p', 'rb') as f:\r\n","    test_data = pickle.load(f)\r\n","\r\n","X_train, y_train = train_data['features'], train_data['labels']\r\n","X_val, y_val = val_data['features'], val_data['labels']\r\n","X_test, y_test = test_data['features'], test_data['labels']\r\n","\r\n","assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels!\"\r\n","assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels!\"\r\n","assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels!\"\r\n","\r\n","assert(X_train.shape[1:] == (32, 32, 3)), \"The dimensions of the images are not 32 x 32 x 3\"\r\n","assert(X_val.shape[1:] == (32, 32, 3)), \"The dimensions of the images are not 32 x 32 x 3\"\r\n","assert(X_test.shape[1:] == (32, 32, 3)), \"The dimensions of the images are not 32 x 32 x 3\"\r\n","\r\n","data = pd.read_csv('/content/german-traffic-signs/signnames.csv')\r\n","\r\n","print(data)\r\n","\r\n","num_of_samples = []\r\n"," \r\n","cols = 5\r\n","num_classes = 43\r\n"," \r\n","# fig, axs = plt.subplots(nrows=num_classes, ncols = cols, figsize=(5, 50))\r\n","# fig.tight_layout()\r\n","# for i in range(cols):\r\n","#     for j, row in data.iterrows():\r\n","#         x_selected = X_train[y_train == j]\r\n","#         axs[j][i].imshow(x_selected[random.randint(0, len(x_selected - 1)), :, :], cmap=plt.get_cmap(\"gray\"))\r\n","#         axs[j][i].axis(\"off\")\r\n","#         if i == 2:\r\n","#             axs[j][i].set_title(str(j) + \"-\" + row[\"SignName\"])\r\n","#             num_of_samples.append(len(x_selected))\r\n","\r\n","# plt.show()\r\n","\r\n","# print(num_of_samples)\r\n","# plt.figure(figsize=(12, 4))\r\n","# plt.bar(range(0, num_classes), num_of_samples)\r\n","# plt.title(\"Distribution of the training dataset\")\r\n","# plt.xlabel(\"Class number\")\r\n","# plt.ylabel(\"Number of images\")\r\n","# plt.show()\r\n","\r\n","def grayscale(img):\r\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","    return img\r\n","\r\n","def equalize(img):\r\n","    img = cv2.equalizeHist(img)\r\n","    return img\r\n","\r\n","def preprocessing(img):\r\n","    img = grayscale(img)\r\n","    img = equalize(img)\r\n","    img = img/255\r\n","    return img\r\n","\r\n","X_train = np.array(list(map(preprocessing, X_train)))\r\n","X_val = np.array(list(map(preprocessing, X_val)))\r\n","X_test = np.array(list(map(preprocessing, X_test)))\r\n","\r\n","X_train = X_train.reshape(34799, 32, 32, 1)\r\n","X_test = X_test.reshape(12630, 32, 32, 1)\r\n","X_val = X_val.reshape(4410, 32, 32, 1)\r\n","\r\n","y_train = to_categorical(y_train, 43)\r\n","y_test = to_categorical(y_test, 43)\r\n","y_val = to_categorical(y_val, 43)"],"outputs":[],"metadata":{"id":"gbS7LY3n8PeA"}},{"cell_type":"code","execution_count":null,"source":["datagen = ImageDataGenerator(width_shift_range=0.1,\r\n","                            height_shift_range=0.1,\r\n","                            zoom_range=0.2,\r\n","                            shear_range=0.1,\r\n","                            rotation_range=10)\r\n","datagen.fit(X_train)\r\n","batches = datagen.flow(X_train, y_train, batch_size=20)\r\n","X_batch, y_batch = next(batches)"],"outputs":[],"metadata":{"id":"4wNgo_64xy22"}},{"cell_type":"code","execution_count":null,"source":["def modified_model():\r\n","    model = Sequential()\r\n","    model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))\r\n","    model.add(Conv2D(60, (5, 5), activation='relu'))\r\n","\r\n","    model.add(Conv2D(30, (3, 3), activation='relu'))\r\n","    model.add(Conv2D(30, (3, 3), activation='relu'))\r\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","    model.add(Flatten())\r\n","    model.add(Dense(500, activation='relu'))\r\n","    model.add(Dropout(0.5))\r\n","    model.add(Dense(num_classes, activation='softmax'))\r\n","    # compile model\r\n","    model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\r\n","    return model\r\n","\r\n","model = modified_model()\r\n","h = model.fit(datagen.flow(X_train, y_train, batch_size=50),\r\n","            steps_per_epoch=X_train.shape[0]/50,\r\n","            epochs=10,\r\n","            validation_data=(X_val, y_val), shuffle=1)\r\n","\r\n","# plt.plot(h.history['accuracy'])\r\n","# plt.plot(h.history['val_accuracy'])\r\n","# plt.xlabel('epoch')\r\n","# plt.legend(['training', 'validation'])\r\n","# plt.title('Accuracy')\r\n","# plt.show()\r\n","\r\n","score = model.evaluate(X_test, y_test, verbose=0)\r\n","\r\n","print('Test score:', score[0])\r\n","print('Test accuracy', score[1])"],"outputs":[],"metadata":{"id":"a8186275","cellView":"code"}},{"cell_type":"code","execution_count":null,"source":["url = 'https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg'\r\n","r = requests.get(url, stream=True)\r\n","img = Image.open(r.raw)\r\n","plt.imshow(img, cmap=plt.get_cmap('gray'))\r\n","plt.show()\r\n","\r\n","#Preprocess image\r\n","img = np.asarray(img)\r\n","img = cv2.resize(img, (32, 32))\r\n","img = preprocessing(img)\r\n","plt.imshow(img, cmap = plt.get_cmap('gray'))\r\n","plt.show()\r\n"," \r\n","#Reshape reshape\r\n","img = img.reshape(1, 32, 32, 1)\r\n","\r\n","#Test image\r\n","prediction = np.argmax(model.predict(img), axis =-1 )\r\n","print(\"predicted sign: \", str(prediction))"],"outputs":[],"metadata":{"id":"zI-i3zWcqjsN"}}]}